{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9653f8e8",
   "metadata": {},
   "source": [
    "# Reddit Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4010ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages \n",
    "import praw\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e906d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing API \n",
    "reddit = praw.Reddit(client_id=\"zs_IJyaVCIFdTJOLOqgHVQ\",#my client id\n",
    "                     client_secret=\"6HOthHWpREuIemp_Y-SOfFbZGWH0eA\",  #your client secret\n",
    "                     user_agent=\"my user agent\", #user agent name\n",
    "                     username = \"test_9876\",     # your reddit username\n",
    "                     password = \"Pileaplante25\")     # your reddit password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1746aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subreddits to scrape from \n",
    "sub = ['Denmark', 'buzzfeedbot', 'newsdk', 'dkpol', 'denmark2', \n",
    "        'scandinavia', 'dankmark', 'InfluencergossipDK', 'Aarhus']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620bedf",
   "metadata": {},
   "source": [
    "Code found on the following website: https://medium.com/swlh/scraping-reddit-using-python-57e61e322486\n",
    "It scrapes the posts on the specified subreddits that contains one of the keywords (specified below). It also scrapes all comments on those posts. \n",
    "\n",
    "It saves each as a CSV continuously. Therefore, it is needed to specify where they should be saved in the bottom of the next chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ab28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sub:\n",
    "    subreddit = reddit.subreddit(s)   # Chosing the subreddit\n",
    "\n",
    "# NOTE: ALL THE POST DATA AND COMMENT DATA WILL BE SAVED IN TWO DIFFERENT\n",
    "#   DATASETS AND LATER CAN BE MAPPED USING IDS OF POSTS/COMMENTS\n",
    "\n",
    "    # uncomments the keywords that you want to search for\n",
    "    query = ['Karen Melchior', 'Sofie Carsten Nielsen', 'Astrid Krag',\n",
    "              'Christel Schaldemose', 'Sophie Løhde', 'Ellen Trane Nørby',\n",
    "              'Pernille Skipper', 'Liselott Blixt', 'Pia Kjærsgaard',\n",
    "              'Pia Olsen Dyhr', 'Margrete Auken', 'Mette Abildgaard', \n",
    "              'Pernille Weiss', 'Pernille Vermund']\n",
    "    \n",
    "    # query = ['Morten Helveg', 'Stinus Lindgreen', 'Benny Engelbrect', \n",
    "    #           'Magnus Heunicke', 'Jan E. Jørgensen', 'Morten Løkkegård',\n",
    "    #           'Jakob Elleman-Jensen', 'Nikolaj Villumsen', 'Rune Lund',\n",
    "    #           'Morten Messerchmidt', 'Rasmus Nordqvist', 'Rasmus Jarlov',\n",
    "    #           'Søren Pape']\n",
    "\n",
    "\n",
    "    for item in query:\n",
    "        post_dict = {\n",
    "            \"title\" : [],\n",
    "            \"score\" : [],\n",
    "            \"id\" : [],\n",
    "            \"url\" : [],\n",
    "            \"comms_num\": [],\n",
    "            \"created\" : [],\n",
    "            \"body\" : [],\n",
    "            \"ups\" : [],\n",
    "            \"downs\" : [],\n",
    "            \"upvote_ratio\" : [],\n",
    "            \"search_keyword\" : []\n",
    "        }\n",
    "        comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_link_id\" : [],\n",
    "            \"score\" : [],\n",
    "            \"search_keyword\" : []\n",
    "        }\n",
    "        for idx, submission in enumerate(subreddit.search(query,sort = \"top\")):\n",
    "            post_dict[\"title\"].append(submission.title)\n",
    "            post_dict[\"score\"].append(submission.score)\n",
    "            post_dict[\"id\"].append(submission.id)\n",
    "            post_dict[\"url\"].append(submission.url)\n",
    "            post_dict[\"comms_num\"].append(submission.num_comments)\n",
    "            post_dict[\"created\"].append(submission.created)\n",
    "            post_dict[\"body\"].append(submission.selftext)\n",
    "            post_dict[\"ups\"].append(submission.ups)\n",
    "            post_dict[\"downs\"].append(submission.downs)\n",
    "            post_dict[\"upvote_ratio\"].append(submission.upvote_ratio)\n",
    "\n",
    "            post_dict[\"ups\"][idx] = math.ceil(post_dict[\"ups\"][idx] * post_dict[\"upvote_ratio\"][idx])\n",
    "            post_dict[\"downs\"][idx] = math.ceil(post_dict[\"score\"][idx] - post_dict[\"ups\"][idx])\n",
    "\n",
    "            post_dict[\"search_keyword\"].append(query)\n",
    "            \n",
    "            ##### Acessing comments on the post\n",
    "            submission.comments.replace_more(limit = 1) \n",
    "            for comment in submission.comments.list():\n",
    "                comments_dict[\"comment_id\"].append(comment.id)\n",
    "                comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "                comments_dict[\"comment_body\"].append(comment.body)\n",
    "                comments_dict[\"comment_link_id\"].append(comment.link_id)\n",
    "                comments_dict[\"score\"].append(comment.score)\n",
    "                comments_dict[\"search_keyword\"].append(query)\n",
    "        \n",
    "        post_comments = pd.DataFrame(comments_dict)\n",
    "        post_comments.to_csv(\"C:/Users/stine/OneDrive/melchior_job/nye_melchior/\" + \"comments_\" + s  + \"_\" + item +\"subreddit.csv\")\n",
    "        \n",
    "        post_data = pd.DataFrame(post_dict)\n",
    "        post_data.to_csv(\"C:/Users/stine/OneDrive/melchior_job/nye_melchior/\" + \"posts_\" + s + \"_\" + item +\"subreddit.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff612e5",
   "metadata": {},
   "source": [
    "## Join CSVs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7230d25",
   "metadata": {},
   "source": [
    "Joins the CSVs according to specified beginning of the files. E.g. joining all CSVs for the female politicians. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406f735",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "os.chdir(\"C:/Users/stine/OneDrive/melchior_job/female_pol_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d8292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all files in directory ending with \".csv\"\n",
    "file_start = 'posts_'\n",
    "all_filenames = [i for i in glob.glob(f\"{file_start}*\")]\n",
    "print(f\"These are all of the filenames starting with posts_ {all_filenames}.\")\n",
    "\n",
    "#combine all cvs files\n",
    "combined_csv_data = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "print(combined_csv_data.shape)\n",
    "\n",
    "combined_csv_data.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "\n",
    "combined_csv_data.to_csv(\"posts_all_female_updated.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
